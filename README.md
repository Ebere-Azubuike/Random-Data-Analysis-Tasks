# Random-Data-Analysis-Tasks
This page houses different tasks and gigs on data analysis.
# Caveat
Please note that you might edit the file path when uploading on your jupyter notebook


Applied Learning Assignments 1:

Write Python code to filter rows where City_Development_Index > 0.8 and Company_Size is greater than 3.
Use iloc to select the first 10 rows and specific columns like Experience and Education_Level.
Group data by Relevant_Experience and calculate the average City_Development_Index for each group.
Group by Company_Size and count the number of unique entries in Last_New_Job.
Analyze the frequency distribution of Company_Type using value_counts().
Identify numerical columns with missing values and fill them using the mean
Drop rows where more than 50% of data is missing, and document the impacton dataset size.
Query the dataset to extract rows where Experience > 10 and Company_Size == 7.
Create a new feature Experience_Gap by subtracting Last_New_Job from Experience.
Normalize City_Development_Index to a 0â€“1 scale and explain the benefits of normalization.
Create new column cdi_per and merge it to the original dataframe using pd.merge and analyze the combined insights.


